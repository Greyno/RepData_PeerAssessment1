?RColorBrewer
display.brewer.pal(Accent)
display.brewer.pal("Accent")
display.brewer.pal(5,"Accent")
display.brewer.pal(5,"Spectral")
?rm
rm(list=ls())
help()
?clear
?summary
help.start
?help
x <- c(10, 11, 12, 13, 14, 15)
y<-c(x,0,x)
ls y
ls()
rm(x1)
x1<-c(1,2)
y2<-(x,0,x)
y2<-(x1,0,x1)
y2<-c(x1,0,x1)
v<-2*x1+y+1
rm(v,x,x1)
rm(x2,x3,y,y2)
x<-c(10,11,12)
y<-c(x,0,x)
v<-2*x+y+1
n<-10
1:n-1
1:(n-1)
?seq
library("xlsx", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
ngData<-read.xlsx("/Users/gamrey/Documents/Coursera work files/ngap.xlsx", sheetIndex=1, header=TRUE)
colIndex<-7:15 #Read columns 7-15
rowIndex<-18:23 #Read rows 18-23
dat<-read.xlsx("/Users/gamrey/Documents/Coursera work files/ngap.xlsx", sheetIndex=1,colIndex=colIndex, rowindex=rowIndex) #Assign the rows and columns to dat vector
dat<-read.xlsx("/Users/gamrey/Documents/Coursera work files/ngap.xlsx", sheetIndex==1,colIndex==colIndex, rowindex==rowIndex) #Assign the rows and columns to dat vector
dat<-read.xlsx("/Users/gamrey/Documents/Coursera work files/ngap.xlsx", sheetIndex=1,colIndex=colIndex, rowIndex=rowIndex) #Assign the rows and columns to dat vector
dat #Print out the information
sum(dat$Zip*dat$Ext,na.rm=T) #Question 3 from quiz 1
dat
library("xlsx", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
initial <-read.csv("/Users/gamrey/Documents/Coursera work files/idaho.csv", nrows=3)
initial
install.packages("xml")
install.packages("XML")
library("XML", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc<-xmlTreeParse(fileUrl,useInternal=TRUE) #Load in the url
doc<-xmlTreeParse(fileUrl,useInternal=TRUE) #Load in the url
fileUrl<-https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
library(XML)
doc<-xmlTreeParse(fileUrl,useInternal=TRUE) #Load in the url
fileUrl<-getURL("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml")
library(RCurl)
install.packages("RCurl")
library(RCurl)
fileUrl<-getURL("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml")
doc<-xmlTreeParse(fileUrl,useInternal=TRUE) #Load in the url
rootNode<-xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[[1]]
node[@attr-name='zipcode']
node[attr-name='zipcode']
node[attr-name=='zipcode']
codes<-xpathSApply(doc,"//li[@class='zipcode']",xmlValue)
codes
codes<-xpathSApply(doc,"//li[@class='name']",xmlValue)
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv" #Load webpage
dt<-fread(fileUrl)
download.file(https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv)
housingData<-[,15]
hData<-housengData[,15]
hData<-housingData[,15]
housingData <-read.csv("/Users/gamrey/Documents/Coursera work files/idaho.csv")
hData<-housingData[,15]
hData
initial<-read.csv("idaho.csv", nrows=2)
initial<-read.csv(housingData, nrows=2)
initial<-read.csv("housingData"/Users/gamrey/Documents/Coursera work files/idaho.csv, nrows=2)
initial<-read.csv("/Users/gamrey/Documents/Coursera work files/idaho.csv", nrows=2)
initial
hData<-housingData[,41]
hData
initial<-read.csv("/Users/gamrey/Documents/Coursera work files/idaho.csv", nrows=4)
initial
fileUrl<-"http://www.w3schools.com/xml/simple.xml"
doc<-xmlTreeParse(fileUrl.useInternal=TRUE)
doc<-xmlTreeParse(fileUrl,useInternal=TRUE)
rootNode<-xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[[1]]
rootNode[[1]][[1]][[1]]
xmlSApply(rootNode,xmlValue)
xpathSApply(rootNode,"//name",xmlValue)
xpathSApply(rootNode,"//price",xmlValue)
fileUrl<-getURL("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml")
doc<-xmlTreeParse(fileUrl,useInternal=TRUE) #Set the info such thta it can be parsed
zipCodes<-xpathSApply(doc,"//li[@class='zipcode']",xmlValue)
zipCodes
zipCodes<-xpathSApply(rootNode,"//zipcode",xmlValue)
zipCodes
rootNode<-xnlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode<-xnlRoot(fielUrl)
rootNode<-xmlRoot(fielUrl)
rootNode<-xmlRoot(fileUrl)
rootNode<-xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[[1]]
rootNode[[1]][[1]]
xpathSApply(rootNode,"//zipcode",xmlValue)
zipCodes<-xpathSApply(rootNode,"//zipcode",xmlValue) #Get the zipcodes
zipCodes
foundCode<-zipCodes==21231
result[foundCode] #Print the codes wtih 21231
result<-foundCode
result
foundCode<-zipCodes==21231 #Find the codes with 21231
result<-zipCodes
result
result<-foundCode
result
result[foundCode] #Print the codes with 21231
result2<-result[foundCode]
resutl2
result2
result2[result]
zipCodes #Print the zipcodes
foundCode<-zipCodes==21231 #Find the codes with 21231
foundCode
result<-foundCode
result2
count.fields(result2)
fileUrl<-getURL("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml")
zipCodes<-xpathSApply(rootNode,"//zipcode",xmlValue) #Find the zipcodes
zipCodes #Print the zipcodes
rootNode<-xmlRoot(doc)
xmlName(rootNode)
foundCode<-zipCodes==21231 #Find the codes with 21231
foundCode
result<-foundCode
result
result<-foundCode
result[foundCode]
result3[foundCode]
result2<-foundCode
result3<-foundCode
result3[foundCode]
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv" #Load webpage
download.file(fileUrl, destfile="./Documents/Coursera work files/survey.csv", method="curl")
DT<-fread(survey.csv)
install.packages("data.table")
library("data.table", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
DT<-fread("survey.csv")
DT<-fread("./Documents/Coursera work files/survey.csv")
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(rowMeans(DT)[DT$SEX==1];rowMeans(DT)[DT$SEX==2])
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean)) #Time 0.001
?rowmeans
?tapply
library("data.table", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
?rowmeans
?tapply
?rowmeans
?sapply
initial <-read.csv("/Users/gamrey/Documents/Coursera work files/idaho.csv", nrows=3)
initial
DT<-fread("./Documents/Coursera work files/survey.csv") #Read the file into DT
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
sapply(split(DT$pwgtp15,DT$SEX),mean)
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT$pwgtp15,by=DT$SEX))
mean(DT$pwgtp15,by=DT$SEX)
mean(DT$pwgtp15,by=DT$SEX)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
tapply(DT$pwgtp15,DT$SEX,mean)
sapply(split(DT$pwgtp15,DT$SEX),mean)
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
mean(DT$pwgtp15,by=DT$SEX)
DT[,mean(pwgtp15),by=SEX]
dt
initial <-read.csv("/Users/gamrey/Documents/Coursera work files/idaho.csv", nrows=100)
initial
initial <-read.csv("/Users/gamrey/Documents/Coursera work files/idaho.csv", nrows=3)
initial
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
rep(0,2)
install.packages("httpuv")
library("httpuv", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
library("httr", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
oauth_endpoints("github")
myapp<-oauth_app("github","2683ff220684816f800072c3f4fa6ff524d24afc", "c413284a820235dedaa0")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
oauth_endpoints("github")
myapp<-oauth_app("github","2683ff220684816f800072c3f4fa6ff524d24afc", "c413284a820235dedaa0")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
myapp<-oauth_app("Coursera API Access","2683ff220684816f800072c3f4fa6ff524d24afc", "c413284a820235dedaa0")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
myapp<-oauth_app("Coursera API Access","2683ff220684816f800072c3f4fa6ff524d24afc", "c413284a820235dedaa0")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
myapp<-oauth_app("Coursera API Access","2683ff220684816f800072c3f4fa6ff524d24afc", "c413284a820235dedaa0")
github_token <- oauth2.0_token(oauth_endpoints("Coursera API Access"), myapp)
myapp<-oauth_app("Coursera API Access","2683ff220684816f800072c3f4fa6ff524d24afc", "c413284a820235dedaa0")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
oauth_endpoints("github")
myapp<-oauth_app("Coursera API Access","2683ff220684816f800072c3f4fa6ff524d24afc", "c413284a820235dedaa0")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
myapp<-oauth_app("Coursera API Access","c413284a820235dedaa0", "2683ff220684816f800072c3f4fa6ff524d24afc")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req<-GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
lapply(req$created_at)
library(jsonlite)
myjson<-fromJSON(content(req))
library(RJSONIO)
myjson<-fromJSON(content(req))
myjson<-fromJSON(toJSON()content(req))
myjson<-fromJSON(toJSON(content(req))
myjson<-fromJSON(toJSON(content(req))
myjson<-fromJSON(toJSON(content(req))
myjson
myjson<-fromJSON(toJSON(content(req)))
myjson
file
head(file)
con=url("http://biostat.jhsph.edu/~jleek/contact.html ")
htmlCode=readLines(con)
close(con) #Close the connection
htmlCode
con=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
htmlCode=readLines(con)
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
download.file(fileUrl, destfile="/Users/gamrey/Documents/Coursera work files/q5.csv", method="curl")
file<- read.csv("/Users/gamrey/Documents/Coursera work files/q5.csv")
file<- read.csv("/Users/gamrey/Documents/Coursera work files/q5.csv", nrows=5)
file
file<- read.csv("/Users/gamrey/Documents/Coursera work files/q5.csv", nrows=7)
file
ff <- tempfile()
cat(file = ff, "123456", "987654", sep = "\n")
read.fwf(ff, widths = c(1,2,3))
read.fwf(file, widths = c(2,3,3))
file<- read.csv("/Users/gamrey/Documents/Coursera work files/q5.csv")
read.fwf(file, widths = c(2,3,3))
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
download.file(fileUrl, destfile="/Users/gamrey/Documents/Coursera work files/q5.csv", method="curl")
file<- read.csv("/Users/gamrey/Documents/Coursera work files/q5.csv")
read.fwf(file, widths = c(2,3,3))
debug(ls)
ls
delta<-abs(x-y) #Get the absolute difference in avg hp
ls
ls
debug(ls)
ls
library(datasets)
data(iris)
virg_subset <- subset(iris, Species == "virginica") #Get all the data for the virginica species
virg_subset[, 1] #Show the virginica values in the first row
apply(iris[,1:4],2,mean) #Apply the Fun(ction) mean over the columns (Margin=2) 1 to 4
virg_subset[, 1] #Show the virginica values in the first row
virg_subset
iris$Species
mean(iris$Sepal.Length)
apply(iris[,1:4],2,mean) #Apply the Fun(ction) mean over the columns (Margin=2) 1 to 4
library(datasets)
data(mtcars)
cyl_subset<-[mtcars, mtcars$cyl]
result<-subset(mtcars, select=c(mpg, cyl)) #Subset by mpg and cyl
with(mtcars, tapply(mpg, cyl, mean)) #Find the mean mpg by cyl value
split(mtcars, mtcars$cyl)
mtcars
with(mtcars, tapply(hp, cyl, mean)) #Find the mean hp by cyl values
result<-subset(mtcars, select=c(hp, cyl))
result2<-subset(result, cyl==8) #Get the 8 cylinder data
result3<-subset(result, cyl==4) #Get the 4 cylinder data
x<-mean(result2[,1]) #Get avg hp for 8 cylinders
y<-mean(result3[,1]) #Get avg hp for 4 cylinders
delta<-abs(x-y) #Get the absolute difference in avg hp
apply(iris[,1:4],2,mean) #Apply the Fun(ction) mean over the columns (Margin=2) 1 to 4
mean(mtcars$mpg, mtcars$cyl)
split(mtcars, mtcars$cyl)
apply(mtcars, 2, mean)
tapply(mtcats$mpg, mtcars$cyl, mean)
tapply(mtcars$mpg, mtcars$cyl, mean)
virg_subset <- subset(iris, Species == "virginica") #Get all the data for the virginica species
virg_subset[, 1] #Show the virginica values in the first row
mean(virg_subset[,1]) #Get the mean of the first column of the subset data
str(virg_subset)
apply(iris[,1:4],2,mean) #Apply the Fun(ction) mean over the columns (Margin=2) 1 to 4
fileURL<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile="/Users/gamrey/Documents/Coursera work files/gdp.csv", method="curl")
download.file(fileURL, destfile="/Users/gamrey/Documents/Coursera work files/gdp.csv", method="curl")
gdpData<-read.csv("/Users/gamrey/Documents/Coursera work files/gdp.csv")
fileURL<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileURL, destfile="/Users/gamrey/Documents/Coursera work files/country.csv", method="curl")
countryData<-read.csv("/Users/gamrey/Documents/Coursera work files/country.csv")
head(gdpData, nrows=3)
head(countryData, nrows=3)
str(gdpData)
str(countryData)
names(gdpData)
names(countryData)
mergedData=merge(gdpData, countryData, by.x="X", by.y="CountyrCode". all=TRUE)
mergedData=merge(gdpData, countryData, by.x="X", by.y="CountyrCode", all=TRUE)
mergedData=merge(gdpData, countryData, by.x="X", by.y="CountryCode", all=TRUE)
head(mergedData, nrows=3)
mergedData=merge(countryData, gdpData, by.x="CountryCode", by.y="X", all=TRUE)
head(mergedData, nrows=3)
names(mergedData)
view(mergedData)
View(mergedData)
View(gdp)
View(gdpData)
View(countryData)
sort(mergedData$Gross.domestic.product.2012)
sort(mergedData$Gross.domestic.product.2012, decreasing=TRUE)
view(sort(mergedData$Gross.domestic.product.2012, decreasing=TRUE))
View(sort(mergedData$Gross.domestic.product.2012, decreasing=TRUE))
mergedData[with(mergedData, order(-Gross.domestic.product.2012))]
mergedData[with(mergedData, order(-"Gross.domestic.product.2012"))]
mergedData[with(mergedData, order(-V2))]
sum(!is.na(unique(mergedData$Gross.domestic.product.2012)))
matches<-sum(!is.na(unique(mergedData$Gross.domestic.product.2012))) #Find matches
matches<-!is.na(unique(mergedData$Gross.domestic.product.2012))
y<-matches[y]
y<-y[matches]
y<-y(matches)
sum(!is.na(unique(mergedData$Gross.domestic.product.2012))) #Find matches
mergedData[order(Gross.domestic.product.2012, decreasing=TRUE), list(CountryCode, Long.Name.x, Long.Name.y,Gross.domestic.product.2012)]
library(plyr)
if (!file.exists("data")) {
dir.create("data")
}
getwd()
testData<-read.table("./data/UCI HAR Dataset/test/X_test.txt")
testData<-read.table("./data/UCI HAR Dataset/test/X_test.txt")
if (!file.exists("data")) {
dir.create("data")
}
testData<-read.table("/data/UCI HAR Dataset/test/X_test.txt")
testData<-read.table("/data/UCI HAR Dataset/test/X_test.txt")
testData<-read.table("~/data/UCI HAR Dataset/test/X_test.txt")
testLabels<-read.table("~data/UCI HAR Dataset/test/Y_test.txt")
testLabels<-read.table("~/data/UCI HAR Dataset/test/Y_test.txt")
testSubjects<-read.table("~/data/UCI HAR Dataset/test/subject_test.txt")
trainingData<-read.table("~data/UCI HAR Dataset/train/X_train.txt")
trainingLabels<-read.table("~data/UCI HAR Dataset/train/Y_train.txt")
trainingData<-read.table("~data/UCI HAR Dataset/train/X_train.txt")
trainingData<-read.table("~/data/UCI HAR Dataset/train/X_train.txt")
trainingLabels<-read.table("~/data/UCI HAR Dataset/train/Y_train.txt")
trainingSubjects<-read.table("~/data/UCI HAR Dataset/train/subject_train.txt")
featuresData<-read.table("~/data/UCI HAR Dataset/features.txt")
activity<-read.table("~/data/UCI HAR Dataset/activity_labels.txt")
write.table(tidyData, file="tidyData.txt", row.names=FALSE)
tidyData<-ddply(editedData, .(subject, activity), function(x) colMeans(x[, 3:68]))
dataSet<-rbind(trainingData, testData)
labelSet<-rbind(trainingLabels, testLabels)
subjectSet<-rbind(trainingSubjects, testSubjects)
featuresData<-read.table("~/data/UCI HAR Dataset/features.txt")
meanAndStd<-grep("mean\\(\\)|std\\(\\)", featuresData[,2])
dataSet<-dataSet[, meanAndStd] #Row of columns numbers that match the grep selections
names(dataSet)<-gsub("\\(\\)","",featuresData[meanAndStd,2])
names(labelSet)<-c("Label") #Change Label column name from V1 to "Label"
names(subjectSet)<-c("Subject") #Change Subject column name from V1 to "Subject"
mergedDataSet<-cbind(subjectSet, labelSet, dataSet)
names(mergedDataSet)<-gsub("-", "", names(mergedDataSet)) #Remove '-' from the names
names(mergedDataSet)<-tolower(names(mergedDataSet)) #Create names in all lower case
activity<-read.table("~/data/UCI HAR Dataset/activity_labels.txt")
activity[,2]<-tolower(activity[,2]) #Change column 2 names to lower case
activity[,2]<-gsub("_", "", activity[,2]) #Remove "_" values from column 2 names
activityLabel<-activity[labelSet[,1],2]
labelSet[,1]<-activityLabel
names(labelSet)<-"activity"
names(subjectSet)<-"subject"
editedData<-cbind(subjectSet, labelSet, dataSet)
dim(editedData)
names(editedData)<-gsub("-", "", names(editedData)) #Remove '-' from the names
names(editedData)<-tolower(names(editedData)) #Create names in all lower case
tidyData<-ddply(editedData, .(subject, activity), function(x) colMeans(x[, 3:68]))
write.table(tidyData, file="tidyData.txt", row.names=FALSE)
write.table(tidyData, file="~/data/tidyData.txt", row.names=FALSE)
View(editedData)
View(mergedDataSet)
set.seed
set.seed(1)
rpois(5,2)
result<-rpois(5,2)
str(result)
set.seed(1)
result<-rpois(5,2)
str(result)
set.seed(10)
x<-rep(0:1, each=5)
e<-rnorm(10, 0,20)
y<-0.5+2*x+e
plot(x,y)
summary(y)
library(datasets)
Rprof()
fit <-lm(y ~ x1+x2)
Rprof(NULL)
summaryRprof()
set.seed(10)
set.seed(10)
x<-rep(0:1, each=5)
e<-rnorm(10, 0,20)
y<-0.5+2*x+e
library(lattice)
setwd("~/Documents/Coursera work files/Reproducible Research/PeerAssessment1")
activity <- read.csv("activity.csv")
activity$date <- as.Date(activity$date, format = "%Y-%m-%d")
activity$interval <- as.factor(activity$interval)
activity_by_day<-aggregate(activity["steps"], by=activity["date"], FUN=sum)
hist(activity_by_day$steps, main=paste("Histogram of Numer of Steps/day (NA values removed)"), xlab="Number of steps per day", ylab="Frequency of steps")
mean_steps<-round(mean_steps<-mean(activity_by_day$steps, na.rm=TRUE), digits=2)
median_steps<-round(median(activity_by_day$steps, na.rm=TRUE))
activity_by_interval<-aggregate(activity["steps"], by=activity["interval"], FUN=mean, na.rm=TRUE)
plot(as.integer(activity_by_interval$interval), activity_by_interval$steps, type="l", ylab="Number of steps", xlab="Interval", main="Avg activity pattern")
max_step <- max(activity_by_interval$steps) #The max step is 206
max_interval <-round(which.max(activity_by_interval$steps))
missing_values <- round(sum(is.na(activity$steps))) #There are 2304 NAs in dataset
replaced_data<-activity #Make a copy of the original dataset
for (i in 1:nrow(replaced_data)) {
if (is.na(replaced_data$steps[i])) {
replaced_data$steps[i] <- activity_by_interval[which(replaced_data$interval[i] == activity_by_interval$interval), ]$steps
}
}
missing_values <- round(sum(is.na(replaced_data$steps))) #There are no NAs in this new dataset
replaced_data_activity_by_day<-aggregate(replaced_data["steps"], by=replaced_data["date"], FUN=sum)
hist(replaced_data_activity_by_day$steps, main=paste("Histogram of Numer of Steps/day (missing values replaced)"), xlab="Number of steps per day", ylab="Frequency of steps")
mean_steps_replaced<-round(mean_steps_replaced<-mean(replaced_data_activity_by_day$steps), digits=2)
median_steps_replaced<-round(median(replaced_data_activity_by_day$steps))
replaced_data_activity_by_day$weekday<-weekdays(replaced_data_activity_by_day$date)
test<-replaced_data_activity_by_day
weekend_data <- subset(test, weekday %in% c("Saturday","Sunday"))
weekday_data <- subset(test, !weekday %in% c("Saturday","Sunday"))
weekend_data$weekday <- ifelse(weekend_data$weekday > "Friday","weekend", "")
weekday_data$weekday <- ifelse(weekday_data$weekday >="Monday","weekday", "weekday")
test_final<-rbind(weekend_data, weekday_data)
head(test_final)
xyplot(test_final.steps ~ date | weekday, data=steps, layout=c(1,1))
head(replaced_data_activity_by_day)
test_by_interval<-aggregate(test_final["steps"], by=test_final["weekday"], FUN=mean)
head(test_by_interval)#Plot the final dataset by weekend and weekday
test_by_interval<-aggregate(test_final["steps"], by=test_final["date"], FUN=mean)
head(test_by_interval)
test_final$interval<-aggregate(test_final["steps"], by=test_final["date"], FUN=mean)
head(test_final)
tail(test_final)
xyplot(test_final.steps ~ interval.steps | weekday, data=steps, layout=c(1,1))
xyplot(test_final ~ interval.steps | weekday, data=steps, layout=c(1,1))
xyplot(test_final ~ interval.steps | weekday, data=interval.steps, layout=c(1,1))
xyplot(test_final ~ interval.steps | weekday, data=test_final.interval.steps, layout=c(1,1))
head(test_final)
ggplot(test_final, aes(x=interval.steps, y=steps)) +
ggplot(test_final, aes(x=interval.steps, y=steps)) +
geom_line(color="violet") +
facet_wrap(~ weekday, nrow=2, ncol=1) +
labs(x="Interval", y="Number of steps") +
theme_bw()
library(ggplot2)
ggplot(test_final, aes(x=interval.steps, y=steps)) +
geom_line(color="violet") +
facet_wrap(~ weekday, nrow=2, ncol=1) +
labs(x="Interval", y="Number of steps") +
theme_bw()
ggplot(test_final, aes(x=steps, y=steps)) +
ggplot(test_final, aes(x=steps, y=steps)) +
geom_line(color="violet") +
facet_wrap(~ weekday, nrow=2, ncol=1) +
labs(x="Interval", y="Number of steps") +
theme_bw()
ggplot(test_final, aes(x=interval.steps, y=steps)) + geom_line(color="violet") + facet_wrap(~ weekday, nrow=2, ncol=1) + labs(x="Interval", y="Number of steps") + theme_bw()
ggplot(test_final, aes(x=test_final$interval.steps, y=steps)) + geom_line(color="violet") + facet_wrap(~ weekday, nrow=2, ncol=1) + labs(x="Interval", y="Number of steps") + theme_bw()
ggplot(test_final, aes(x=test_final$interval.steps, y=steps)) + geom_line(color="violet") + facet_wrap(~ weekday, nrow=2, ncol=1) + labs(x="Interval", y="Number of steps") + theme_bw()
ggplot(test_final, aes(x=test_final$interval.steps, y=steps)) + geom_line(color="violet") + facet_wrap(~ weekday, nrow=2, ncol=1) + labs(x="Interval", y="Number of steps")
ggplot(test_final, aes(x=date, y=steps)) + geom_line(color="violet") + facet_wrap(~ weekday, nrow=2, ncol=1) + labs(x="Interval", y="Number of steps") + theme_bw()
ggplot(test_final, aes(x=date, y=steps)) + geom_line(color="black") + facet_wrap(~ weekday, nrow=2, ncol=1) + labs(x="Interval", y="Number of steps") + theme_bw()
ggplot(test_final, aes(x=interval.steps, y=steps)) + geom_line(color="black") + facet_wrap(~ weekday, nrow=2, ncol=1) + labs(x="Interval", y="Number of steps") + theme_bw()
str(test_final)
ggplot(test_final, aes(x=interval, y=steps)) + geom_line(color="black") + facet_wrap(~ weekday, nrow=2, ncol=1) + labs(x="Interval", y="Number of steps") + theme_bw()
ggplot(test_final, aes(x=date, y=steps)) + geom_line(color="black") + facet_wrap(~ weekday, nrow=2, ncol=1) + labs(x="Interval", y="Number of steps") + theme_bw()
ggplot(test_final, aes(x=date, y=interval.steps)) + geom_line(color="black") + facet_wrap(~ weekday, nrow=2, ncol=1) + labs(x="Interval", y="Number of steps") + theme_bw()
ggplot(test_final, aes(x=date, y=steps)) + geom_line(color="black") + facet_wrap(~ weekday, nrow=2, ncol=1) + labs(x="Interval", y="Number of steps") + theme_bw()
ggplot(test_final, aes(x=steps, y=date)) + geom_line(color="black") + facet_wrap(~ weekday, nrow=2, ncol=1) + labs(x="Interval", y="Number of steps") + theme_bw()
ggplot(test_final, aes(x=date, y=steps)) + geom_line(color="black") + facet_wrap(~ weekday, nrow=2, ncol=1) + labs(x="Interval", y="Number of steps") + theme_bw()
